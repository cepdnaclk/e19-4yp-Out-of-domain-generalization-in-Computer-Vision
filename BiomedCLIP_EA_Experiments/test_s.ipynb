{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37006710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/embedding-gecko-001', display_name='Embedding Gecko', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1024, output_token_limit=1, supported_actions=['embedText', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.0-pro-vision-latest', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-pro-vision', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-latest', display_name='Gemini 1.5 Pro Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-001', display_name='Gemini 1.5 Pro 001', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-002', display_name='Gemini 1.5 Pro 002', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro', display_name='Gemini 1.5 Pro', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-latest', display_name='Gemini 1.5 Flash Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001', display_name='Gemini 1.5 Flash 001', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001-tuning', display_name='Gemini 1.5 Flash 001 Tuning', description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=16384, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createTunedModel'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash', display_name='Gemini 1.5 Flash', description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-002', display_name='Gemini 1.5 Flash 002', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b', display_name='Gemini 1.5 Flash-8B', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-001', display_name='Gemini 1.5 Flash-8B 001', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-latest', display_name='Gemini 1.5 Flash-8B Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0827', display_name='Gemini 1.5 Flash 8B Experimental 0827', description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0924', display_name='Gemini 1.5 Flash 8B Experimental 0924', description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-exp-03-25', display_name='Gemini 2.5 Pro Experimental 03-25', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-03-25', display_name='Gemini 2.5 Pro Preview 03-25', description='Gemini 2.5 Pro Preview 03-25', version='2.5-preview-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-05-20', display_name='Gemini 2.5 Flash Preview 05-20', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-05-20', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17-thinking', display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-05-06', display_name='Gemini 2.5 Pro Preview 05-06', description='Preview release (May 6th, 2025) of Gemini 2.5 Pro', version='2.5-preview-05-06', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp', display_name='Gemini 2.0 Flash Experimental', description='Gemini 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash', display_name='Gemini 2.0 Flash', description='Gemini 2.0 Flash', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-001', display_name='Gemini 2.0 Flash 001', description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp-image-generation', display_name='Gemini 2.0 Flash (Image Generation) Experimental', description='Gemini 2.0 Flash (Image Generation) Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-001', display_name='Gemini 2.0 Flash-Lite 001', description='Stable version of Gemini 2.0 Flash Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite', display_name='Gemini 2.0 Flash-Lite', description='Gemini 2.0 Flash-Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-preview-image-generation', display_name='Gemini 2.0 Flash Preview Image Generation', description='Gemini 2.0 Flash Preview Image Generation', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview-02-05', display_name='Gemini 2.0 Flash-Lite Preview 02-05', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview', display_name='Gemini 2.0 Flash-Lite Preview', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp', display_name='Gemini 2.0 Pro Experimental', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp-02-05', display_name='Gemini 2.0 Pro Experimental 02-05', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-exp-1206', display_name='Gemini Experimental 1206', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-01-21', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-1219', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-tts', display_name='Gemini 2.5 Flash Preview TTS', description='Gemini 2.5 Flash Preview TTS', version='gemini-2.5-flash-exp-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-tts', display_name='Gemini 2.5 Pro Preview TTS', description='Gemini 2.5 Pro Preview TTS', version='gemini-2.5-pro-preview-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=65536, output_token_limit=65536, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/learnlm-2.0-flash-experimental', display_name='LearnLM 2.0 Flash Experimental', description='LearnLM 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=32768, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-1b-it', display_name='Gemma 3 1B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-4b-it', display_name='Gemma 3 4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-12b-it', display_name='Gemma 3 12B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-27b-it', display_name='Gemma 3 27B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=131072, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3n-e4b-it', display_name='Gemma 3n E4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=2048, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/embedding-001', display_name='Embedding 001', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/text-embedding-004', display_name='Text Embedding 004', description='Obtain a distributed representation of a text.', version='004', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-embedding-exp-03-07', display_name='Gemini Embedding Experimental 03-07', description='Obtain a distributed representation of a text.', version='exp-03-07', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=1, supported_actions=['embedContent', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-embedding-exp', display_name='Gemini Embedding Experimental', description='Obtain a distributed representation of a text.', version='exp-03-07', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=1, supported_actions=['embedContent', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list().page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea0c47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "prompts: list[tuple[str, str]] = [\n",
      "    ('No perineural invasion and normal lymphoid pattern.', 'Perineural invasion with cells arranged in irregular patterns.'),\n",
      "    ('No prominent nucleoli and no plasmacytoid differentiation.', 'Prominent nucleoli and evidence of plasmacytoid differentiation.'),\n",
      "    ('Normal lymphoid pattern with no epithelial cells.', 'Sheets of epithelial cells disrupting the normal lymphoid pattern.'),\n",
      "    ('No apoptosis and no giant cells.', 'Presence of apoptosis and multinucleated giant cells.'),\n",
      "    ('No evidence of clear cell morphology and no lobular structures.', 'Presence of clear cell morphology and distinct lobular structures.'),\n",
      "    ('No evidence of perineural invasion and no evidence of apoptosis.', 'Evidence of perineural invasion and presence of apoptosis.'),\n",
      "    ('Cells in normal lymphoid pattern, no prominent nucleoli.', 'Cells in sheets, prominent and irregular nucleoli.'),\n",
      "    ('No plasmacytoid differentiation, no evidence of giant cells.', 'Evidence of plasmacytoid differentiation and presence of giant cells.'),\n",
      "    ('No epithelial cells, no clear cell morphology.', 'Presence of epithelial cells and clear cell morphology.'),\n",
      "    ('No lobular structures, normal lymphoid arrangement.', 'Presence of lobular structures and irregular cell arrangement.'),\n",
      "    ('Absence of tumor cells invading nerves.', 'Tumor cells clearly infiltrating around nerves.'),\n",
      "    ('Nucleoli are inconspicuous.', 'Nucleoli are markedly enlarged and atypical.'),\n",
      "    ('Lymphocytes appear organized and normal.', 'Lymphocytes are disorganized and forming abnormal clusters.'),\n",
      "    ('No signs of cell death.', 'Cells exhibiting features of programmed cell death.'),\n",
      "    ('No unusually large cells are seen.', 'Multinucleated cells are readily identifiable.'),\n",
      "    ('The tissue lacks any epithelial components.', 'Epithelial cells are present within the lymphoid tissue.'),\n",
      "    ('Cells do not show a plasma cell-like appearance.', 'Cells demonstrate characteristics of plasma cells.'),\n",
      "    ('The architecture is not characterized by lobules.', 'Distinct lobular formations are visible.'),\n",
      "    ('No evidence of cellular changes suggesting malignancy.', 'Clear indications of malignant cellular transformation are present.'),\n",
      "    ('The cells are arranged in a typical, non-cancerous fashion.', 'The cells are arranged in an atypical, cancerous fashion.')\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "from API_KEY import GEMINI_API_KEY\n",
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "for i in range(1):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemma-3-27b-it\", contents=\"\"\"The task is to generate textual descriptions pairs of visual discriminative features to identify whether the central region of an histopathological image patch contains tumor tissue or not.\\\n",
    "              The patch is extracted from an H&E‑stained whole‑slide image of a lymph node section.\n",
    "                Here are the best performing pairs in descending order. High scores indicate higher quality visual discriminative features.\n",
    "                    Current Top 10 prompt pairs:\n",
    "                        1. ('No evidence of perineural invasion.', 'Evidence of perineural invasion by tumor cells.'), Score: 90\n",
    "                        2. ('No prominent nucleoli.', 'Prominent, large, and irregular nucleoli.'), Score: 87\n",
    "                        3. ('No evidence of epithelial cells.', 'Presence of epithelial cells.'), Score: 80\n",
    "                        4. ('Cells are arranged in a normal lymphoid pattern.', 'Cells are arranged in sheets, nests, or irregular patterns.'), Score: 73\n",
    "                        5. ('No evidence of plasmacytoid differentiation.', 'Evidence of plasmacytoid differentiation.'), Score: 69\n",
    "                        6. ('No evidence of giant cells.', 'Presence of multinucleated giant cells.'), Score: 61\n",
    "                        7. ('No evidence of apoptosis.', 'Presence of apoptosis.'), Score: 50\n",
    "                        8. ('No evidence of lymphoid aggregates.', 'Presence of lymphoid aggregates.'), Score: 43\n",
    "                        9. ('No evidence of clear cell morphology.', 'Presence of clear cell morphology.'), Score: 33\n",
    "                        10. ('No evidence of lobular structures.', 'Presence of lobular structures.'), Score: 20\n",
    "                Write 20 new prompt pairs as follows to make the score as high as possible:\n",
    "                    1-10 by combining multiple medical concepts only from the above prompts \n",
    "                    11-20 with different language style and same medical concepts. Each pair should have distinct language style.\n",
    "                Only give the output as python code in the format - prompts: list[tuple[negative: str, positive: str]]\"\"\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5e62b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response on attempt 1: 1. **Cross over the prompts:**\n",
      "\n",
      "   * **Prompt 1 (P1):** \"Small mature lymphocytes centrally show no indication of active replication.\"\n",
      "   * **Prompt 2 (P2):** \"Large immature cells centrally demonstrate ongoing active replication.\"\n",
      "   * **Prompt 3 (P3):** \"Small, mature lymphocytes centrally show no active processes of chromosome separation.\"\n",
      "   * **Prompt 4 (P4):** \"Large, immature cells centrally demonstrate active processes of chromosome separation.\"\n",
      "\n",
      "   Let's combine elements from P1 and P3 for the first part of the new prompt, and P2 and P4 for the second part. We can focus on the core ideas of maturity/immaturity and the presence/absence of replication/division.\n",
      "\n",
      "   **New Prompt (Crossover):** \"Small, mature lymphocytes centrally show no signs of active replication or chromosome separation, while large, immature cells centrally demonstrate active replication and chromosome separation.\"\n",
      "\n",
      "2. **Mutate the prompt generated in Step 1 and generate a final prompt pair:**\n",
      "\n",
      "   Now, let's mutate the crossover prompt to create a more concise and impactful pair. We want to highlight the contrast more starkly and perhaps use slightly different phrasing.\n",
      "\n",
      "   **Final Prompt Pair (Mutation):**\n",
      "\n",
      "   * **Prompt A:** \"Mature, small lymphocytes exhibit no central evidence of proliferation.\"\n",
      "   * **Prompt B:** \"Immature, large cells centrally display vigorous proliferative activity.\"\n",
      "\n",
      "   This pair simplifies the language (\"proliferation\" instead of \"replication or chromosome separation\"), maintains the core contrast (mature/immature, small/large, no activity/vigorous activity), and uses slightly varied vocabulary to make each prompt distinct yet complementary.\n",
      "\n",
      "The final prompt pair is:\n",
      "('Mature, small lymphocytes exhibit no central evidence of proliferation.', 'Immature, large cells centrally display vigorous proliferative activity.')...\n",
      "[Warning] get_prompt_pairs parse error on attempt 1/10: No ```python ... ``` block found\n",
      "Raw response on attempt 2: 1.  **Cross over the prompts:**\n",
      "\n",
      "    The common themes across the prompt pairs are:\n",
      "    * **Cell size and maturity:** \"Small mature lymphocytes\" vs. \"Large immature cells.\"\n",
      "    * **Central location:** \"centrally show/demonstrate.\"\n",
      "    * **Cellular activity/replication:** \"no indication of active replication,\" \"ongoing active replication,\" \"no active processes of chromosome separation,\" \"active processes of chromosome separation.\"\n",
      "\n",
      "    Let's combine these elements to create a new prompt. We can take \"Small mature lymphocytes centrally show no indication of active replication\" and \"Large, immature cells centrally demonstrate active processes of chromosome separation.\"\n",
      "\n",
      "    A new prompt could be: **\"Small mature lymphocytes centrally exhibit no signs of active replication, whereas large immature cells centrally display active processes of cell division.\"**\n",
      "\n",
      "2.  **Mutate the prompt and generate a final prompt pair:**\n",
      "\n",
      "    Let's refine the generated prompt and create a contrasting pair. We can focus on the core difference between the cells' replicative status.\n",
      "\n",
      "    * For the first part, we can simplify \"no signs of active replication\" to \"quiescent.\"\n",
      "    * For the second part, \"active processes of cell division\" can be more specifically described as \"robust mitotic activity.\"\n",
      "\n",
      "    This leads to the final prompt pair:\n",
      "\n",
      "    ('Small, mature lymphocytes centrally appear quiescent.', 'Large, immature cells centrally demonstrate robust mitotic activity.')...\n",
      "[Warning] get_prompt_pairs parse error on attempt 2/10: No ```python ... ``` block found\n",
      "Raw response on attempt 3: 1. **Cross over the prompts:**\n",
      "\n",
      "Let's take elements from all four prompts to create a new one. We can combine the \"small mature lymphocytes\" and \"large immature cells\" dichotomy with aspects of \"active replication\" and \"chromosome separation.\"\n",
      "\n",
      "New prompt idea: \"Small, mature lymphocytes centrally show no signs of active replication or chromosome separation, while large, immature cells centrally demonstrate active replication and chromosome separation.\"\n",
      "\n",
      "2. **Mutate the new prompt and generate a final prompt pair:**\n",
      "\n",
      "Now, let's mutate this into a pair. We want to maintain the core contrast but introduce slight variations in wording or emphasis.\n",
      "\n",
      "* For the first part, we can simplify \"active replication or chromosome separation\" to a more general term for cell division.\n",
      "* For the second part, we can emphasize the *presence* of these active processes.\n",
      "\n",
      "Final Prompt Pair:\n",
      "('Small, mature lymphocytes centrally exhibit no evidence of active cell division.', 'Large, immature cells centrally demonstrate pronounced active cell division.')...\n",
      "[Warning] get_prompt_pairs parse error on attempt 3/10: No ```python ... ``` block found\n",
      "Raw response on attempt 4: 1. **Cross over the prompts:**\n",
      "\n",
      "Let's combine elements from all four prompts to create a new one that incorporates the ideas of replication, chromosome separation, cell size, maturity, and central location. A good crossover prompt would be:\n",
      "\n",
      "\"Small, mature lymphocytes centrally show no active replication or chromosome separation.\"\n",
      "\n",
      "The counterpart to this new prompt should reflect the opposite characteristics, drawing from the \"large immature cells\" and \"active replication/chromosome separation\" aspects. So the second prompt in the pair would be:\n",
      "\n",
      "\"Large, immature cells centrally demonstrate active replication and chromosome separation.\"\n",
      "\n",
      "2. **Mutate the prompt generated in Step 1:**\n",
      "\n",
      "Now, let's mutate the prompt pair:\n",
      "(\"Small, mature lymphocytes centrally show no active replication or chromosome separation.\", \"Large, immature cells centrally demonstrate active replication and chromosome separation.\")\n",
      "\n",
      "We can refine the wording to be more concise and perhaps slightly more scientific in its phrasing, while maintaining the core meaning.\n",
      "\n",
      "* For the first prompt, instead of \"no active replication or chromosome separation,\" we could say \"lacking active proliferation\" or \"exhibiting no signs of proliferation.\"\n",
      "* For the second prompt, \"demonstrate active replication and chromosome separation\" could be \"undergoing active proliferation\" or \"displaying active mitotic processes.\"\n",
      "\n",
      "Let's go with a slight mutation to emphasize the process more directly.\n",
      "\n",
      "Mutated Prompt Pair:\n",
      "('Small, mature lymphocytes centrally lack active proliferation.', 'Large, immature cells centrally demonstrate active mitotic processes.')...\n",
      "[Warning] get_prompt_pairs parse error on attempt 4/10: No ```python ... ``` block found\n",
      "Raw response on attempt 5: 1. **Crossover:**\n",
      "\n",
      "Let's break down the shared and differing elements of the prompts:\n",
      "\n",
      "* **Shared Core:** \"Small... lymphocytes centrally\" and \"Large... cells centrally\" seem to be the consistent structural elements.\n",
      "* **Varying Descriptors:**\n",
      "    * \"mature\" vs. \"immature\"\n",
      "    * \"no indication of active replication\" vs. \"ongoing active replication\"\n",
      "    * \"no active processes of chromosome separation\" vs. \"active processes of chromosome separation\"\n",
      "\n",
      "To cross them over, we can combine the ideas of \"replication\" and \"chromosome separation\" as they are closely related processes indicative of cell division.\n",
      "\n",
      "New Prompt (Crossover): \"Small, mature lymphocytes centrally show no active signs of replication or chromosome separation.\"\n",
      "\n",
      "2. **Mutate:**\n",
      "\n",
      "Now, let's mutate the crossover prompt to create a final pair. We'll maintain the contrasting nature.\n",
      "\n",
      "Final Prompt Pair:\n",
      "('Small, mature lymphocytes centrally exhibit no active processes of cellular proliferation.', 'Large, immature cells centrally demonstrate active processes of cellular proliferation.')...\n",
      "[Warning] get_prompt_pairs parse error on attempt 5/10: No ```python ... ``` block found\n",
      "Raw response on attempt 6: 1. **Cross over the prompts:**\n",
      "\n",
      "Let's combine elements from all four prompts to create a new one. The common themes are cell size, maturity, central activity, and replication/chromosome separation.\n",
      "\n",
      "* From Prompt Pair 1: \"Small mature lymphocytes centrally show no indication of active replication.\"\n",
      "* From Prompt Pair 1: \"Large immature cells centrally demonstrate ongoing active replication.\"\n",
      "* From Prompt Pair 2: \"Small, mature lymphocytes centrally show no active processes of chromosome separation.\"\n",
      "* From Prompt Pair 2: \"Large, immature cells centrally demonstrate active processes of chromosome separation.\"\n",
      "\n",
      "A good crossover would synthesize these ideas. Let's aim for a prompt that reflects the core distinction: small, mature, inactive vs. large, immature, active.\n",
      "\n",
      "New Prompt (Crossover): \"Small, mature cells centrally show no active processes of replication or chromosome separation, while large, immature cells centrally demonstrate active processes of replication and chromosome separation.\"\n",
      "\n",
      "2. **Mutate the prompt and generate a final prompt pair:**\n",
      "\n",
      "Now, let's mutate the crossover prompt to create a refined pair. We want to maintain the core meaning but perhaps make it more concise or introduce slight variations in wording for the positive and negative cases.\n",
      "\n",
      "Original Crossover: \"Small, mature cells centrally show no active processes of replication or chromosome separation, while large, immature cells centrally demonstrate active processes of replication and chromosome separation.\"\n",
      "\n",
      "Let's break it into two distinct statements for the pair and refine the language.\n",
      "\n",
      "* For the \"no active processes\" part, we can simplify \"no active processes of replication or chromosome separation\" to something like \"no active proliferation.\"\n",
      "* For the \"active processes\" part, we can similarly simplify to \"active proliferation.\"\n",
      "\n",
      "Final Prompt Pair:\n",
      "('Small, mature cells centrally show no active proliferation.', 'Large, immature cells centrally demonstrate active proliferation.')...\n",
      "[Warning] get_prompt_pairs parse error on attempt 6/10: No ```python ... ``` block found\n",
      "Raw response on attempt 7: 1. **Crossover:**\n",
      "\n",
      "Let's break down the common elements and differences in the provided prompt pairs.\n",
      "\n",
      "* **Commonality:** Both pairs describe the characteristics of cells, specifically lymphocytes and \"large, immature cells,\" focusing on their central activity related to replication or chromosome separation. The structure \"Small [adjective] cells centrally show no [activity]\" and \"Large [adjective] cells centrally demonstrate [activity]\" is consistent.\n",
      "\n",
      "* **Differences:**\n",
      "    * Prompt Pair 1 uses \"active replication.\"\n",
      "    * Prompt Pair 2 uses \"active processes of chromosome separation.\"\n",
      "    * The adjectives for lymphocytes are \"mature\" and \"mature.\"\n",
      "\n",
      "To cross them over, we can combine the concepts. Let's aim for a prompt that synthesizes the idea of cellular division or proliferation. \"Active replication\" is a broader term that encompasses \"chromosome separation.\"\n",
      "\n",
      "A new prompt from crossing over could be:\n",
      "\n",
      "* \"Small, mature lymphocytes centrally show no indication of active cellular division.\"\n",
      "* \"Large, immature cells centrally demonstrate ongoing active cellular division.\"\n",
      "\n",
      "2.  **Mutate:**\n",
      "\n",
      "Now, let's mutate this new prompt to refine it. We can make the language more precise or introduce a slightly different nuance while maintaining the core contrast.\n",
      "\n",
      "Consider alternatives for \"cellular division\" or ways to describe the \"no indication\" and \"ongoing active\" parts.\n",
      "\n",
      "* Instead of \"ongoing active cellular division,\" we could use something like \"robust mitotic activity\" or \"significant proliferative activity.\"\n",
      "* Instead of \"no indication of active cellular division,\" we could use \"lack proliferative capacity\" or \"exhibit no mitotic figures.\"\n",
      "\n",
      "Let's try to make the second part of the prompt a bit more specific regarding the *type* of activity, while keeping the first part concise.\n",
      "\n",
      "**Final Prompt Pair:**\n",
      "\n",
      "```python\n",
      "(\"Small, mature lymphocytes centrally exhibit no proliferative activity.\", \"Large, immature cells centrally demonstrate robust mitotic figures.\")\n",
      "```...\n",
      "Loaded 2 prompt-pairs.\n",
      "First pair: Small, mature lymphocytes centrally exhibit no proliferative activity.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Small, mature lymphocytes centrally exhibit no proliferative activity.',\n",
       " 'Large, immature cells centrally demonstrate robust mitotic figures.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_and_parse_prompt_list(code: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    From a string of Python code, finds the first occurrence of\n",
    "        = [ ... ]\n",
    "    and parses that bracketed literal into a List[Tuple[str,str]].\n",
    "\n",
    "    Raises:\n",
    "        ValueError if no list literal is found or it’s malformed.\n",
    "    \"\"\"\n",
    "    # 1) grab everything from the first '=' up to the matching ']' \n",
    "    m = re.search(r'=\\s*(\\[\\s*[\\s\\S]*?\\])', code)\n",
    "    if not m:\n",
    "        raise ValueError(\"No list literal found after an '=' in the code\")\n",
    "    list_str = m.group(1)\n",
    "\n",
    "    # 2) safely evaluate it (only literals)\n",
    "    try:\n",
    "        data: Any = ast.literal_eval(list_str)\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        raise ValueError(f\"Malformed list literal: {e}\")\n",
    "\n",
    "    # 3) validate shape\n",
    "    if not isinstance(data, list) or not all(\n",
    "        isinstance(item, (list, tuple)) and len(item) == 2 for item in data\n",
    "    ):\n",
    "        raise ValueError(\"Parsed object is not a list of 2-element lists/tuples\")\n",
    "\n",
    "    # 4) convert to List[Tuple[str,str]]\n",
    "    return [(str(a), str(b)) for a, b in data]\n",
    "\n",
    "def extract_and_parse_prompt_tuple(code: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    From a string of Python code, finds the first literal tuple of two strings\n",
    "    (e.g. (\"neg prompt\",\"pos prompt\")) and returns it as (str, str).\n",
    "\n",
    "    Raises:\n",
    "        ValueError if no suitable 2-element string tuple is found.\n",
    "    \"\"\"\n",
    "    # Parse into an AST\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    # Walk the tree looking for a Tuple node with exactly two string constants\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Tuple) and len(node.elts) == 2:\n",
    "            a, b = node.elts\n",
    "            if (\n",
    "                isinstance(a, ast.Constant) and isinstance(a.value, str)\n",
    "                and isinstance(b, ast.Constant) and isinstance(b.value, str)\n",
    "            ):\n",
    "                return (a.value, b.value)\n",
    "\n",
    "    raise ValueError(\"No 2-element string tuple found in code\")\n",
    "\n",
    "import io\n",
    "import tokenize\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "\n",
    "def _force_double_quotes(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Rewrites every Python string-literal in `code` to use double-quotes,\n",
    "    properly handling apostrophes and other special characters.\n",
    "    \"\"\"\n",
    "    tokens = tokenize.generate_tokens(io.StringIO(code).readline)\n",
    "    new_tokens = []\n",
    "    for toknum, tokval, start, end, line in tokens:\n",
    "        if toknum == tokenize.STRING:\n",
    "            # Get the actual string value\n",
    "            value = ast.literal_eval(tokval)\n",
    "\n",
    "            # Create a new string literal with double quotes\n",
    "            # Properly escape any double quotes or backslashes in the string\n",
    "            # This automatically handles escaping correctly\n",
    "            tokval = json.dumps(value)\n",
    "\n",
    "        new_tokens.append((toknum, tokval))\n",
    "    return tokenize.untokenize(new_tokens)\n",
    "\n",
    "\n",
    "def get_prompt_pairs(prompt, client, parse_func=extract_and_parse_prompt_list,  max_retries=10) -> List[Tuple[str, str]]:\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = client.generate_content(prompt)\n",
    "            raw = response.text\n",
    "            print(f\"Raw response on attempt {attempt}: {raw}...\")\n",
    "\n",
    "            # 1) extract the python block\n",
    "\n",
    "            m = re.search(r'```python\\s*([\\s\\S]*?)\\s*```', raw)\n",
    "            if not m:\n",
    "                raise ValueError(\"No ```python ... ``` block found\")\n",
    "            code = m.group(1)\n",
    "\n",
    "            # 2) normalize all literals to double-quoted form\n",
    "            code = _force_double_quotes(code)\n",
    "\n",
    "            # print(f\"Normalized code on attempt {attempt}: {code}...\")\n",
    "\n",
    "            # 3) convert the string to a list of tuples\n",
    "            prompts_list = parse_func(code)\n",
    "            prompts: List[Tuple[str, str]] = prompts_list \n",
    "            print(f\"Loaded {len(prompts)} prompt-pairs.\")\n",
    "            print(\"First pair:\", prompts[0])\n",
    "            return prompts\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"[Warning] get_prompt_pairs parse error on attempt {attempt}/{max_retries}: {e}\")\n",
    "            if attempt == max_retries:\n",
    "                raise RuntimeError(\n",
    "                    \"Failed to parse prompts after multiple attempts\") from e\n",
    "            # otherwise, retry immediately\n",
    "\n",
    "    # Should never reach here\n",
    "    raise RuntimeError(\"Unreachable\")\n",
    "\n",
    "meta_init_prompt = \"\"\"Please follow the instruction step-by-step to generate a better prompt pair.\n",
    "1. Cross over the following prompts and generate a new prompt:\n",
    "\n",
    "Prompt Pair 1: ('Small mature lymphocytes centrally show no indication of active replication.', 'Large immature cells centrally demonstrate ongoing active replication.')\n",
    "Prompt Pair 2: ('Small, mature lymphocytes centrally show no active processes of chromosome separation.', 'Large, immature cells centrally demonstrate active processes of chromosome separation.')\n",
    "\n",
    "2. Mutate the prompt generated in Step 1 and generate a final prompt pair in a python tuple (str, str)\"\"\"\n",
    "\n",
    "get_prompt_pairs(meta_init_prompt, client, parse_func=extract_and_parse_prompt_tuple)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
