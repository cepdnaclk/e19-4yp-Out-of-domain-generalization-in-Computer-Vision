{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37006710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/embedding-gecko-001', display_name='Embedding Gecko', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1024, output_token_limit=1, supported_actions=['embedText', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.0-pro-vision-latest', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-pro-vision', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-latest', display_name='Gemini 1.5 Pro Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-001', display_name='Gemini 1.5 Pro 001', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-002', display_name='Gemini 1.5 Pro 002', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro', display_name='Gemini 1.5 Pro', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-latest', display_name='Gemini 1.5 Flash Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001', display_name='Gemini 1.5 Flash 001', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001-tuning', display_name='Gemini 1.5 Flash 001 Tuning', description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=16384, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createTunedModel'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash', display_name='Gemini 1.5 Flash', description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-002', display_name='Gemini 1.5 Flash 002', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b', display_name='Gemini 1.5 Flash-8B', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-001', display_name='Gemini 1.5 Flash-8B 001', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-latest', display_name='Gemini 1.5 Flash-8B Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0827', display_name='Gemini 1.5 Flash 8B Experimental 0827', description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0924', display_name='Gemini 1.5 Flash 8B Experimental 0924', description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-exp-03-25', display_name='Gemini 2.5 Pro Experimental 03-25', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-03-25', display_name='Gemini 2.5 Pro Preview 03-25', description='Gemini 2.5 Pro Preview 03-25', version='2.5-preview-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-05-20', display_name='Gemini 2.5 Flash Preview 05-20', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-05-20', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17-thinking', display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-05-06', display_name='Gemini 2.5 Pro Preview 05-06', description='Preview release (May 6th, 2025) of Gemini 2.5 Pro', version='2.5-preview-05-06', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-06-05', display_name='Gemini 2.5 Pro Preview', description='Preview release (June 5th, 2025) of Gemini 2.5 Pro', version='2.5-preview-06-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp', display_name='Gemini 2.0 Flash Experimental', description='Gemini 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash', display_name='Gemini 2.0 Flash', description='Gemini 2.0 Flash', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-001', display_name='Gemini 2.0 Flash 001', description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp-image-generation', display_name='Gemini 2.0 Flash (Image Generation) Experimental', description='Gemini 2.0 Flash (Image Generation) Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-001', display_name='Gemini 2.0 Flash-Lite 001', description='Stable version of Gemini 2.0 Flash Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite', display_name='Gemini 2.0 Flash-Lite', description='Gemini 2.0 Flash-Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-preview-image-generation', display_name='Gemini 2.0 Flash Preview Image Generation', description='Gemini 2.0 Flash Preview Image Generation', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview-02-05', display_name='Gemini 2.0 Flash-Lite Preview 02-05', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview', display_name='Gemini 2.0 Flash-Lite Preview', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp', display_name='Gemini 2.0 Pro Experimental', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp-02-05', display_name='Gemini 2.0 Pro Experimental 02-05', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-exp-1206', display_name='Gemini Experimental 1206', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-01-21', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-1219', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-tts', display_name='Gemini 2.5 Flash Preview TTS', description='Gemini 2.5 Flash Preview TTS', version='gemini-2.5-flash-exp-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-tts', display_name='Gemini 2.5 Pro Preview TTS', description='Gemini 2.5 Pro Preview TTS', version='gemini-2.5-pro-preview-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=65536, output_token_limit=65536, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/learnlm-2.0-flash-experimental', display_name='LearnLM 2.0 Flash Experimental', description='LearnLM 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=32768, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-1b-it', display_name='Gemma 3 1B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-4b-it', display_name='Gemma 3 4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-12b-it', display_name='Gemma 3 12B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-27b-it', display_name='Gemma 3 27B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=131072, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3n-e4b-it', display_name='Gemma 3n E4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=2048, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/embedding-001', display_name='Embedding 001', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/text-embedding-004', display_name='Text Embedding 004', description='Obtain a distributed representation of a text.', version='004', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-embedding-exp-03-07', display_name='Gemini Embedding Experimental 03-07', description='Obtain a distributed representation of a text.', version='exp-03-07', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=1, supported_actions=['embedContent', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list().page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ea0c47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's analyze the situation. The previous instruction (\"Write 10 new prompt pairs that are different from the old ones and has a score as high as possible.\") didn't yield significant improvement. The high-scoring prompts consistently focus on *specific morphological changes* indicative of malignancy – things like nuclear features, mitotic activity, architectural disruption, and presence of atypical cells. Simply asking for \"different\" prompts doesn't guide the generation towards these crucial features.\n",
      "\n",
      "The goal is to generate prompts that highlight *discriminative* features. We need to focus on characteristics that strongly suggest tumor presence *versus* normal lymph node tissue. The best prompts aren't just \"tumor cells are different,\" but *how* they are different.\n",
      "\n",
      "Considering the exemplar instructions, the \"combining multiple medical concepts\" and \"expanding each prompt by appending expert biomedical knowledge\" approaches seem promising. However, let's refine this. We need to focus on features that pathologists *actively look for* when diagnosing lymphoma.  We also need to consider features that might be subtle but diagnostically important.\n",
      "\n",
      "Here's a new instruction:\n",
      "\n",
      "```xml\n",
      "<instruction>\n",
      "Write 10 new prompt pairs. Each pair should describe a contrast between normal lymph node morphology and features indicative of lymphoma, focusing on cellular and architectural characteristics.  Specifically, for each pair:\n",
      "\n",
      "1.  The first prompt should describe a feature typically observed in *normal* lymph node tissue.\n",
      "2.  The second prompt should describe a *corresponding altered feature* strongly suggestive of lymphoma, including details about cellular atypia, architectural distortion, or specific immunophenotypic characteristics (even if visually inferred from H&E staining – e.g., \"cells with a 'blast' appearance suggestive of B-cell lineage\").\n",
      "3.  Prioritize features related to nuclear morphology (size, shape, chromatin pattern, nucleoli), cytoplasmic features, and the organization of cells within the tissue.\n",
      "4.  Aim for prompts that would be useful for a pathologist making a diagnosis.\n",
      "5.  Avoid overly general terms like \"inflammation\" unless specifically qualified (e.g., \"predominantly eosinophilic inflammation\").\n",
      "</instruction>\n",
      "```\n",
      "\n",
      "**Reasoning:**\n",
      "\n",
      "*   **Specificity:** This instruction explicitly asks for contrasts between normal and abnormal features, guiding the generation towards discriminative characteristics.\n",
      "*   **Pathologist Focus:**  It emphasizes features pathologists use, increasing the likelihood of generating relevant prompts.\n",
      "*   **Detailed Features:** It directs attention to key morphological areas (nuclear, cytoplasmic, architectural) known to be important in lymphoma diagnosis.\n",
      "*   **Subtle Cues:** The inclusion of \"immunophenotypic characteristics (even if visually inferred)\" encourages prompts that capture subtle visual cues hinting at specific lymphoma subtypes.\n",
      "*   **Avoids Generality:** Discourages vague prompts that don't provide strong discriminatory power.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "from API_KEY import GEMINI_API_KEY\n",
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "for i in range(1):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemma-3-27b-it\", contents=\"\"\"The task is to generate textual descriptions pairs of visual discriminative features to identify whether the central region of an histopathological image patch contains tumor tissue or not. The patch is extracted from an H&E‑stained whole‑slide image of a lymph node section.\n",
    "    Here are the best performing pairs in ascending order. High scores indicate higher quality visual discriminative features.\n",
    "\n",
    "Current Top 10 prompt pairs:\n",
    "('Scant background inflammation.', 'Prominent lymphoplasmacytic infiltrate surrounding tumor nests.'), Score: 60\n",
    "('Normal lymphocyte morphology.', 'Presence of Reed-Sternberg cells or Hodgkin-like cells.'), Score: 61\n",
    "('Normal mitotic activity.', 'Increased mitotic rate with atypical mitotic figures.'), Score: 63\n",
    "('Lymphocytes arranged in organized follicles.', 'Tumor cells growing in sheets with loss of follicular architecture.'), Score: 69\n",
    "('No necrosis observed.', 'Areas of tumor necrosis with karyorrhexis.'), Score: 70\n",
    "('Uniformly sized and shaped lymphocytes.', 'Pleomorphic lymphocytes with irregular nuclei.'), Score: 71\n",
    "('No emperipolesis.', 'Emperipolesis - intact lymphocytes within tumor cells.'), Score: 75\n",
    "('Scant cytoplasm in lymphocytes.', 'Abundant and eosinophilic cytoplasm in tumor cells.'), Score: 76\n",
    "('No evidence of necrosis.', 'Areas of tumor necrosis with karyorrhexis.'), Score: 79\n",
    "('No prominent nucleoli.', 'Large, prominent nucleoli within tumor cell nuclei.'), Score: 90\n",
    "\n",
    "Last Instruction: Write 10 new prompt pairs that are different from the old ones and has a score as high as possible.\n",
    "The last instruction did not improve the score significantly, so we need to change our approach.\n",
    "\n",
    "This instruction will be used in the following setting:\n",
    "\"<Problem Description and task to be performed>\n",
    "<Current Top 10 Prompts: ....>\n",
    "<Instruction>\"\n",
    "\n",
    "Exemplar Instructions:\n",
    "Write 10 new prompt pairs that are different from the old ones and has a score as high as possible.\n",
    "Write 10 new prompt pairs that are more similar to the high scoring prompts\n",
    "Write 10 new prompt pairs by paraphrasing each of the above. Each pair should have distinct language style.\n",
    "Write 10 new prompt pairs appending rare or borderline patterns which are easily misclassified to score as high as possible.\n",
    "Write 10 new prompt pairs by combining multiple medical concepts.\n",
    "Write 10 new prompt pairs expanding each prompt by appending expert biomedical knowledge.\n",
    "Write 10 new prompt pairs that adds quantitative cues to the qualitative prompts given above.\n",
    "\n",
    "Get creative and write a new generalized instruction to improve the score.\n",
    "Output in a <instruction> tag. Let's think step-by-step,\n",
    "\"\"\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bead94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's analyze the existing prompt pairs and formulate a strategy to generate new, high-scoring ones.\n",
      "\n",
      "**Strategy:**\n",
      "\n",
      "The top-performing pairs generally focus on:\n",
      "\n",
      "*   **Clear contrasts:**  The negative and positive statements are distinctly different and easily observable.\n",
      "*   **Specific pathological features:** They don't just say \"tumor present\" but *how* it's present (necrosis, pleomorphism, mucin, etc.).\n",
      "*   **Quantifiable/Observable changes:** \"Frequent\" vs. \"Rare\", \"Abundant\" vs. \"No evidence\", \"Increased\" vs. \"No increase\".\n",
      "*   **Features related to tumor-stroma interaction:** Lymphoid depletion, desmoplasia.\n",
      "\n",
      "We need to identify features that are commonly altered in lymph node metastases and formulate contrasting pairs.  I'll focus on features related to cell morphology, architecture, and the immune response. I'll also try to incorporate features that are relatively easy for a pathologist to recognize.\n",
      "\n",
      "Here are 10 new prompt pairs, aiming for scores above 80:\n",
      "\n",
      "```python\n",
      "prompts: list[tuple[str, str]] = [\n",
      "    ('Lymphocytes are predominantly small and mature.', 'Lymphocytes are reactive and show immunoblastic morphology.'),\n",
      "    ('Capsule is intact and well-defined.', 'Capsule is breached by tumor infiltration.'),\n",
      "    ('Germinal centers are present and organized.', 'Germinal centers are disrupted and effaced by tumor.'),\n",
      "    ('No evidence of angiolymphatic invasion.', 'Tumor cells are present within lymphatic and blood vessels.'),\n",
      "    ('Sinus histiocytes are unremarkable.', 'Sinus histiocytes exhibit erythrophagocytosis.'),\n",
      "    ('No atypical cells are identified.', 'Presence of atypical lymphoid cells with irregular nuclei.'),\n",
      "    ('No fibrosis is present in the stroma.', 'Significant stromal fibrosis and collagen deposition are observed.'),\n",
      "    ('No granulomas are present.', 'Presence of non-caseating granulomas surrounding tumor cells.'),\n",
      "    ('The architecture is preserved.', 'The architecture is completely distorted by tumor infiltration.'),\n",
      "    ('No plasma cells are observed.', 'Increased number of plasma cells, some exhibiting Dutcher bodies.')\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "from API_KEY import GEMINI_API_KEY\n",
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "for i in range(1):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemma-3-27b-it\", contents=\"\"\"The task is to generate distinct textual descriptions pairs of visual discriminative features to identify whether the central region of an histopathological image patch contains tumor tissue or not. The patch is extracted from an H&E‑stained whole‑slide image of a lymph node section.\n",
    "    Here are the best performing pairs in ascending order. High scores indicate higher quality visual discriminative features.\n",
    "\n",
    "Current Top 10 prompt pairs:\n",
    "1. ('Stroma is collagenous and sparsely cellular.', 'Stroma is desmoplastic and densely cellular with tumor infiltration.'), Score: 60\n",
    "2. ('Mitotic activity is rare and normal.', 'Mitotic activity is frequent and abnormal (atypical mitoses).'), Score: 60\n",
    "3. ('Sinuses show normal flow.', 'Sinuses are obstructed by tumor cells.'), Score: 64\n",
    "4. ('No evidence of necrosis or karyorrhexis.', 'Presence of tumor cell necrosis and karyorrhexis.'), Score: 65\n",
    "5. ('No evidence of extracellular mucin.', 'Abundant extracellular mucin production by tumor cells.'), Score: 72\n",
    "6. ('No emperipolesis.', 'Tumor cells exhibiting emperipolesis (intracellular invasion of lymphocytes).'), Score: 78\n",
    "7. ('Cells exhibit uniform morphology.', 'Cells exhibit marked pleomorphism and variation in size and shape.'), Score: 83\n",
    "8. ('No increased eosinophilic cytoplasm.', 'Increased eosinophilic cytoplasm in tumor cells.'), Score: 85\n",
    "9. ('No increase in mitotic activity.', 'Increased mitotic activity and frequent mitoses are observed.'), Score: 86\n",
    "10. ('No evidence of tumor-induced lymphoid depletion.', 'Lymphoid depletion around tumor nests.'), Score: 90\n",
    "\n",
    "Write 10 new prompt pairs different to above to improve the score, think slowly and formulate a strategy. \n",
    "Output as python code in the format - prompts: list[tuple[negative: str, positive: str]]. Let's think step-by-step.\n",
    "\"\"\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38b03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
