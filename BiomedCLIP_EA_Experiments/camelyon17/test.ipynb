{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37006710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/embedding-gecko-001', display_name='Embedding Gecko', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1024, output_token_limit=1, supported_actions=['embedText', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.0-pro-vision-latest', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-pro-vision', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-latest', display_name='Gemini 1.5 Pro Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-001', display_name='Gemini 1.5 Pro 001', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-002', display_name='Gemini 1.5 Pro 002', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro', display_name='Gemini 1.5 Pro', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-latest', display_name='Gemini 1.5 Flash Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001', display_name='Gemini 1.5 Flash 001', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001-tuning', display_name='Gemini 1.5 Flash 001 Tuning', description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=16384, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createTunedModel'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash', display_name='Gemini 1.5 Flash', description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-002', display_name='Gemini 1.5 Flash 002', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b', display_name='Gemini 1.5 Flash-8B', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-001', display_name='Gemini 1.5 Flash-8B 001', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-latest', display_name='Gemini 1.5 Flash-8B Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0827', display_name='Gemini 1.5 Flash 8B Experimental 0827', description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0924', display_name='Gemini 1.5 Flash 8B Experimental 0924', description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-exp-03-25', display_name='Gemini 2.5 Pro Experimental 03-25', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-03-25', display_name='Gemini 2.5 Pro Preview 03-25', description='Gemini 2.5 Pro Preview 03-25', version='2.5-preview-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-05-20', display_name='Gemini 2.5 Flash Preview 05-20', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-05-20', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17-thinking', display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-05-06', display_name='Gemini 2.5 Pro Preview 05-06', description='Preview release (May 6th, 2025) of Gemini 2.5 Pro', version='2.5-preview-05-06', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-06-05', display_name='Gemini 2.5 Pro Preview', description='Preview release (June 5th, 2025) of Gemini 2.5 Pro', version='2.5-preview-06-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp', display_name='Gemini 2.0 Flash Experimental', description='Gemini 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash', display_name='Gemini 2.0 Flash', description='Gemini 2.0 Flash', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-001', display_name='Gemini 2.0 Flash 001', description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp-image-generation', display_name='Gemini 2.0 Flash (Image Generation) Experimental', description='Gemini 2.0 Flash (Image Generation) Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-001', display_name='Gemini 2.0 Flash-Lite 001', description='Stable version of Gemini 2.0 Flash Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite', display_name='Gemini 2.0 Flash-Lite', description='Gemini 2.0 Flash-Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-preview-image-generation', display_name='Gemini 2.0 Flash Preview Image Generation', description='Gemini 2.0 Flash Preview Image Generation', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview-02-05', display_name='Gemini 2.0 Flash-Lite Preview 02-05', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview', display_name='Gemini 2.0 Flash-Lite Preview', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp', display_name='Gemini 2.0 Pro Experimental', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp-02-05', display_name='Gemini 2.0 Pro Experimental 02-05', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-exp-1206', display_name='Gemini Experimental 1206', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-01-21', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-1219', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-tts', display_name='Gemini 2.5 Flash Preview TTS', description='Gemini 2.5 Flash Preview TTS', version='gemini-2.5-flash-exp-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-tts', display_name='Gemini 2.5 Pro Preview TTS', description='Gemini 2.5 Pro Preview TTS', version='gemini-2.5-pro-preview-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=65536, output_token_limit=65536, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/learnlm-2.0-flash-experimental', display_name='LearnLM 2.0 Flash Experimental', description='LearnLM 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=32768, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-1b-it', display_name='Gemma 3 1B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-4b-it', display_name='Gemma 3 4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-12b-it', display_name='Gemma 3 12B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-27b-it', display_name='Gemma 3 27B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=131072, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3n-e4b-it', display_name='Gemma 3n E4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=2048, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/embedding-001', display_name='Embedding 001', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/text-embedding-004', display_name='Text Embedding 004', description='Obtain a distributed representation of a text.', version='004', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-embedding-exp-03-07', display_name='Gemini Embedding Experimental 03-07', description='Obtain a distributed representation of a text.', version='exp-03-07', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=1, supported_actions=['embedContent', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list().page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e123e091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An histopathological image of a <> region.',\n",
       " 'The central area shows features consistent with <> tissue.',\n",
       " 'This lymph node patch displays characteristics of a <> infiltrate.',\n",
       " 'Observe the cellular morphology within this <> area.',\n",
       " 'The predominant feature of this patch is <> architecture.',\n",
       " 'The nuclear pleomorphism is indicative of a <> process.',\n",
       " 'The staining intensity suggests a <> composition.',\n",
       " 'The density of cells in this region is typical of <> tissue.',\n",
       " 'The presence of mitotic figures suggests a <> state.',\n",
       " 'The stromal reaction is characteristic of <> involvement.',\n",
       " 'The overall pattern is consistent with a <> response.',\n",
       " 'This patch exhibits features of <> lymphocytes.',\n",
       " 'The arrangement of cells suggests a <> origin.',\n",
       " 'The size and shape of nuclei are consistent with <> cells.',\n",
       " 'The cytoplasm staining is indicative of a <> phenotype.',\n",
       " 'The presence of necrosis suggests a <> condition.',\n",
       " 'The inflammatory response appears to be <>.',\n",
       " 'The vascularity within this region is typical of <> tissue.',\n",
       " 'The fibrosis observed is consistent with <> changes.',\n",
       " 'The cellularity is markedly increased in this <> area.',\n",
       " 'The nuclei are hyperchromatic in this <> region.',\n",
       " 'The architectural pattern is disrupted in the <> tissue.',\n",
       " 'The stromal component is prominent in this <> patch.',\n",
       " 'The overall impression is that of a <> process.',\n",
       " 'The cells exhibit atypical features consistent with <> cells.',\n",
       " 'The presence of giant cells suggests a <> reaction.',\n",
       " 'The distribution of cells is uniform in this <> area.',\n",
       " 'The nuclei are round and regular in this <> tissue.',\n",
       " 'The cytoplasm is abundant in these <> cells.',\n",
       " 'The staining is pale in this <> region.',\n",
       " 'The cellular borders are distinct in this <> area.',\n",
       " 'The nuclei are vesicular in this <> tissue.',\n",
       " 'The architectural pattern is well-preserved in the <> tissue.',\n",
       " 'The stromal component is sparse in this <> patch.',\n",
       " 'The overall impression is that of a <> response.',\n",
       " 'The cells exhibit features of <> differentiation.',\n",
       " 'The presence of lymphocytes suggests a <> response.',\n",
       " 'The distribution of cells is irregular in this <> area.',\n",
       " 'The nuclei are irregular in shape in this <> tissue.',\n",
       " 'The cytoplasm is scant in these <> cells.',\n",
       " 'The staining is intense in this <> region.',\n",
       " 'The cellular borders are indistinct in this <> area.',\n",
       " 'The nuclei are densely packed in this <> tissue.',\n",
       " 'The architectural pattern is disorganized in the <> tissue.',\n",
       " 'The stromal component is dense in this <> patch.',\n",
       " 'The overall impression is that of a <> process.',\n",
       " 'The cells show evidence of <> activity.',\n",
       " 'The presence of plasma cells suggests a <> response.',\n",
       " 'The arrangement of cells is follicular in this <> area.',\n",
       " 'The nuclei are enlarged in this <> tissue.',\n",
       " 'The cytoplasm is eosinophilic in these <> cells.',\n",
       " 'The staining is granular in this <> region.',\n",
       " 'The cellular morphology is consistent with <> cells.',\n",
       " 'The nuclei are binucleated in this <> tissue.',\n",
       " 'The architectural pattern is nodular in the <> tissue.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "def extract_and_parse_multi_class_prompt_list(code: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    From a string of Python code, finds the first occurrence of\n",
    "        = [ ... ]\n",
    "    and parses that bracketed literal into a List[str].\n",
    "\n",
    "    The string in the list contains a placeholder <>,\n",
    "\n",
    "    Raises:\n",
    "        ValueError if no list literal is found or it’s malformed,\n",
    "                   or if the parsed list does not contain only strings.\n",
    "    \"\"\"\n",
    "    # 1) Grab everything from the first '=' up to the matching ']'\n",
    "    # This regex is made more robust to handle various whitespace and content within the list.\n",
    "    m = re.search(r'=\\s*(\\[[^\\]]*\\])', code, re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"No list literal found after an '=' in the code\")\n",
    "    list_str = m.group(1)\n",
    "\n",
    "    # 2) Safely evaluate it (only literals)\n",
    "    try:\n",
    "        data: Any = ast.literal_eval(list_str)\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        raise ValueError(f\"Malformed list literal: {e}\")\n",
    "\n",
    "    # 3) Validate shape: ensure it's a list of strings\n",
    "    if not isinstance(data, list) or not all(isinstance(item, str) for item in data):\n",
    "        raise ValueError(\n",
    "            \"Parsed object is not a list of strings, or contains non-string elements.\"\n",
    "        )\n",
    "\n",
    "    # 4) Return the list of strings\n",
    "    return data\n",
    "\n",
    "code = \"\"\"prompts: list[str] = [\n",
    "    \"An histopathological image of a <> region.\",\n",
    "    \"The central area shows features consistent with <> tissue.\",\n",
    "    \"This lymph node patch displays characteristics of a <> infiltrate.\",\n",
    "    \"Observe the cellular morphology within this <> area.\",\n",
    "    \"The predominant feature of this patch is <> architecture.\",\n",
    "    \"The nuclear pleomorphism is indicative of a <> process.\",\n",
    "    \"The staining intensity suggests a <> composition.\",\n",
    "    \"The density of cells in this region is typical of <> tissue.\",\n",
    "    \"The presence of mitotic figures suggests a <> state.\",\n",
    "    \"The stromal reaction is characteristic of <> involvement.\",\n",
    "    \"The overall pattern is consistent with a <> response.\",\n",
    "    \"This patch exhibits features of <> lymphocytes.\",\n",
    "    \"The arrangement of cells suggests a <> origin.\",\n",
    "    \"The size and shape of nuclei are consistent with <> cells.\",\n",
    "    \"The cytoplasm staining is indicative of a <> phenotype.\",\n",
    "    \"The presence of necrosis suggests a <> condition.\",\n",
    "    \"The inflammatory response appears to be <>.\",\n",
    "    \"The vascularity within this region is typical of <> tissue.\",\n",
    "    \"The fibrosis observed is consistent with <> changes.\",\n",
    "    \"The cellularity is markedly increased in this <> area.\",\n",
    "    \"The nuclei are hyperchromatic in this <> region.\",\n",
    "    \"The architectural pattern is disrupted in the <> tissue.\",\n",
    "    \"The stromal component is prominent in this <> patch.\",\n",
    "    \"The overall impression is that of a <> process.\",\n",
    "    \"The cells exhibit atypical features consistent with <> cells.\",\n",
    "    \"The presence of giant cells suggests a <> reaction.\",\n",
    "    \"The distribution of cells is uniform in this <> area.\",\n",
    "    \"The nuclei are round and regular in this <> tissue.\",\n",
    "    \"The cytoplasm is abundant in these <> cells.\",\n",
    "    \"The staining is pale in this <> region.\",\n",
    "    \"The cellular borders are distinct in this <> area.\",\n",
    "    \"The nuclei are vesicular in this <> tissue.\",\n",
    "    \"The architectural pattern is well-preserved in the <> tissue.\",\n",
    "    \"The stromal component is sparse in this <> patch.\",\n",
    "    \"The overall impression is that of a <> response.\",\n",
    "    \"The cells exhibit features of <> differentiation.\",\n",
    "    \"The presence of lymphocytes suggests a <> response.\",\n",
    "    \"The distribution of cells is irregular in this <> area.\",\n",
    "    \"The nuclei are irregular in shape in this <> tissue.\",\n",
    "    \"The cytoplasm is scant in these <> cells.\",\n",
    "    \"The staining is intense in this <> region.\",\n",
    "    \"The cellular borders are indistinct in this <> area.\",\n",
    "    \"The nuclei are densely packed in this <> tissue.\",\n",
    "    \"The architectural pattern is disorganized in the <> tissue.\",\n",
    "    \"The stromal component is dense in this <> patch.\",\n",
    "    \"The overall impression is that of a <> process.\",\n",
    "    \"The cells show evidence of <> activity.\",\n",
    "    \"The presence of plasma cells suggests a <> response.\",\n",
    "    \"The arrangement of cells is follicular in this <> area.\",\n",
    "    \"The nuclei are enlarged in this <> tissue.\",\n",
    "    \"The cytoplasm is eosinophilic in these <> cells.\",\n",
    "    \"The staining is granular in this <> region.\",\n",
    "    \"The cellular morphology is consistent with <> cells.\",\n",
    "    \"The nuclei are binucleated in this <> tissue.\",\n",
    "    \"The architectural pattern is nodular in the <> tissue.\"\n",
    "]\"\"\"\n",
    "extract_and_parse_multi_class_prompt_list(code=code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea0c47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's formulate a strategy to generate high-scoring prompts, and then implement it in Python.\n",
      "\n",
      "**Strategy:**\n",
      "\n",
      "The current top prompts focus on broad descriptions of the tissue and its context (lymph node, biopsy).  To improve, we need to:\n",
      "\n",
      "1. **Specificity:**  Move beyond just \"tissue\" and mention cellular characteristics. Histopathology is about *cells*.\n",
      "2. **Discriminative Features:** Focus on features that *differentiate* tumor from normal.  This means things like cellularity, nuclear features (size, shape, staining), mitotic activity, and architectural patterns.\n",
      "3. **Actionable Verbs:** Use verbs that encourage detailed description (\"assess\", \"evaluate\", \"describe\").  \"Characterize\" is good, but we can do better.\n",
      "4. **Avoid Redundancy:**  Ensure the new prompts are distinct from the existing ones.\n",
      "5. **Contextualize:** Keep the lymph node context, as that's important.\n",
      "\n",
      "Here are some ideas for features to include:\n",
      "\n",
      "*   **Cellularity:**  Dense vs. sparse cell populations.\n",
      "*   **Nuclear Morphology:**  Nuclear size, shape, chromatin pattern, nucleoli.\n",
      "*   **Mitotic Activity:** Presence or absence of dividing cells.\n",
      "*   **Inflammation:** Presence and type of inflammatory cells.\n",
      "*   **Necrosis:** Presence of dead cells.\n",
      "*   **Architectural Pattern:** Disorganized vs. organized structure.\n",
      "*   **Lymphocyte subtypes:** Presence of specific lymphocyte populations.\n",
      "\n",
      "**Python Code:**\n",
      "\n",
      "```python\n",
      "prompts: list[str] = [\n",
      "    \"Describe the cellularity and nuclear morphology of the <> tissue within a lymph node.\",\n",
      "    \"Assess the presence and characteristics of any atypical cells in this <> lymph node section.\",\n",
      "    \"Evaluate the architectural pattern and stromal features of the <> tissue in the lymph node.\",\n",
      "    \"Characterize the degree of lymphocyte infiltration and any evidence of inflammation in the <> region of the lymph node.\",\n",
      "    \"Describe the nuclear-to-cytoplasmic ratio and chromatin texture of cells in the <> lymph node tissue.\",\n",
      "    \"Identify and quantify any mitotic figures present in the <> tissue from a lymph node biopsy.\",\n",
      "    \"Assess for the presence of necrosis or other signs of cell death within the <> lymph node area.\",\n",
      "    \"Describe the distribution and morphology of lymphocytes in the <> region of the lymph node.\",\n",
      "    \"Evaluate the uniformity of cell size and shape within the <> tissue of a lymph node section.\",\n",
      "    \"Characterize the stromal reaction and its relationship to the cellular components in the <> lymph node tissue.\"\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "from API_KEY import GEMINI_API_KEY\n",
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "for i in range(1):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemma-3-27b-it\", contents=\"\"\"The task is to generate distinct textual description prompts of visual discriminative features to describe the central region of an histopathological image patch. The patch is extracted from an H&E‑stained whole‑slide image of a lymph node section. The patch can be either tumor or normal tissue.\n",
    "Each prompt should have a placeholder <> that can be replaced with either \"tumor\" or \"normal\". I will fill in the placeholder later.\n",
    "Here are the best performing pairs in ascending order. High scores indicate higher quality visual discriminative features.\n",
    "Current Top 10 Prompts:\n",
    "1. An histopathological image of a <> lymph node section. Score: 80\n",
    "2. A high-magnification view of <> tissue from a lymph node biopsy. Score: 75\n",
    "3. Characterize the stromal components and their relationship to the <> Score: 74\n",
    "\n",
    "Write 10 new prompts that are different to from the old ones and has a score as high as possible. Formulate a strategy\n",
    "Output as python code in the format - prompts: list[prompt:str]. Let's think step-by-step\n",
    "\"\"\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28bead94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a Python code block containing a list of 50 distinct textual description prompts designed to describe the central region of an H&E-stained histopathological image patch from a lymph node, with a placeholder `<>` for \"tumor\" or \"normal\".  I've aimed for variety in the features described (cellularity, nuclear characteristics, architectural patterns, stromal features, etc.) and phrasing.\n",
      "\n",
      "```python\n",
      "prompts: list[str] = [\n",
      "    \"An histopathological image of a <> region.\",\n",
      "    \"The central area shows features consistent with <> tissue.\",\n",
      "    \"This lymph node patch displays characteristics of a <> infiltrate.\",\n",
      "    \"Observe the cellular morphology within this <> area.\",\n",
      "    \"The predominant feature of this patch is <> architecture.\",\n",
      "    \"The nuclear pleomorphism is indicative of a <> process.\",\n",
      "    \"The staining intensity suggests a <> composition.\",\n",
      "    \"The density of cells in this region is typical of <> tissue.\",\n",
      "    \"The presence of mitotic figures suggests a <> state.\",\n",
      "    \"The stromal reaction is characteristic of <> involvement.\",\n",
      "    \"The overall pattern is consistent with a <> response.\",\n",
      "    \"This patch exhibits features of <> lymphocytes.\",\n",
      "    \"The arrangement of cells suggests a <> origin.\",\n",
      "    \"The size and shape of nuclei are consistent with <> cells.\",\n",
      "    \"The cytoplasm staining is indicative of a <> phenotype.\",\n",
      "    \"The presence of necrosis suggests a <> condition.\",\n",
      "    \"The inflammatory response appears to be <>.\",\n",
      "    \"The vascularity within this region is typical of <> tissue.\",\n",
      "    \"The fibrosis observed is consistent with <> changes.\",\n",
      "    \"The cellularity is markedly increased in this <> area.\",\n",
      "    \"The nuclei are hyperchromatic in this <> region.\",\n",
      "    \"The architectural pattern is disrupted in the <> tissue.\",\n",
      "    \"The stromal component is prominent in this <> patch.\",\n",
      "    \"The overall impression is that of a <> process.\",\n",
      "    \"The cells exhibit atypical features consistent with <> cells.\",\n",
      "    \"The presence of giant cells suggests a <> reaction.\",\n",
      "    \"The distribution of cells is uniform in this <> area.\",\n",
      "    \"The nuclei are round and regular in this <> tissue.\",\n",
      "    \"The cytoplasm is abundant in these <> cells.\",\n",
      "    \"The staining is pale in this <> region.\",\n",
      "    \"The cellular borders are distinct in this <> area.\",\n",
      "    \"The nuclei are vesicular in this <> tissue.\",\n",
      "    \"The architectural pattern is well-preserved in the <> tissue.\",\n",
      "    \"The stromal component is sparse in this <> patch.\",\n",
      "    \"The overall impression is that of a <> response.\",\n",
      "    \"The cells exhibit features of <> differentiation.\",\n",
      "    \"The presence of lymphocytes suggests a <> response.\",\n",
      "    \"The distribution of cells is irregular in this <> area.\",\n",
      "    \"The nuclei are irregular in shape in this <> tissue.\",\n",
      "    \"The cytoplasm is scant in these <> cells.\",\n",
      "    \"The staining is intense in this <> region.\",\n",
      "    \"The cellular borders are indistinct in this <> area.\",\n",
      "    \"The nuclei are densely packed in this <> tissue.\",\n",
      "    \"The architectural pattern is disorganized in the <> tissue.\",\n",
      "    \"The stromal component is dense in this <> patch.\",\n",
      "    \"The overall impression is that of a <> process.\",\n",
      "    \"The cells show evidence of <> activity.\",\n",
      "    \"The presence of plasma cells suggests a <> response.\",\n",
      "    \"The arrangement of cells is follicular in this <> area.\",\n",
      "    \"The nuclei are enlarged in this <> tissue.\",\n",
      "    \"The cytoplasm is eosinophilic in these <> cells.\",\n",
      "    \"The staining is granular in this <> region.\",\n",
      "    \"The cellular morphology is consistent with <> cells.\",\n",
      "    \"The nuclei are binucleated in this <> tissue.\",\n",
      "    \"The architectural pattern is nodular in the <> tissue.\"\n",
      "]\n",
      "```\n",
      "\n",
      "Key improvements and explanations:\n",
      "\n",
      "* **Variety:** The prompts cover a wide range of histopathological features.  I've included prompts relating to cellularity, nuclear features (pleomorphism, hyperchromasia, size, shape, vesicularity), architectural patterns (disrupted, preserved, follicular, nodular), stromal features (fibrosis, density), staining intensity, and the presence of specific cell types (lymphocytes, plasma cells, giant cells).\n",
      "* **Meaningful with Placeholder:** Each prompt makes grammatical and logical sense when you replace `<>` with either \"tumor\" or \"normal\".\n",
      "* **Specificity:**  I've tried to use terms that are commonly used in histopathology reports.\n",
      "* **Python Format:** The code is directly executable and provides the output in the requested `list[str]` format.\n",
      "* **Step-by-step thought process:** I started by listing key features to look for in histopathology images. Then, I created sentence templates that incorporated these features, ensuring the placeholder could be filled in logically.  I then expanded on these templates to create 50 distinct prompts.\n",
      "* **Avoidance of Bias:** The prompts are designed to be neutral and not lead the model towards a specific classification.  They simply *describe* features.\n",
      "* **Lymph Node Focus:** The prompts are tailored to lymph node tissue, referencing features commonly seen in that context.\n",
      "This revised response provides a much more comprehensive and useful set of prompts for your task.  It's designed to be directly usable in your image analysis pipeline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "from API_KEY import GEMINI_API_KEY\n",
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "for i in range(1):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemma-3-27b-it\", contents=\"\"\"The task is to generate 50 distinct textual description prompts of visual discriminative features to describe the central region of an histopathological image patch. The patch is extracted from an H&E‑stained whole‑slide image of a lymph node section. The patch can be either tumor or normal tissue.\n",
    "Each prompt should have a placeholder <> that can be replaced with either \"tumor\" or \"normal\". The text should be meaningful after filling in the placeholder.\n",
    "\n",
    "Eg: An histopathological image of a <>.\n",
    "Output as python code in the format - prompts: list[prompt:str]. Let's think step-by-step\n",
    "\"\"\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38b03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
