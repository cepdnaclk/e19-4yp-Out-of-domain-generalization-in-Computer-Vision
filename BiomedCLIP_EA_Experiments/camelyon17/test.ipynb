{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37006710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/embedding-gecko-001', display_name='Embedding Gecko', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1024, output_token_limit=1, supported_actions=['embedText', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.0-pro-vision-latest', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-pro-vision', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-latest', display_name='Gemini 1.5 Pro Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-001', display_name='Gemini 1.5 Pro 001', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro-002', display_name='Gemini 1.5 Pro 002', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-pro', display_name='Gemini 1.5 Pro', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-latest', display_name='Gemini 1.5 Flash Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001', display_name='Gemini 1.5 Flash 001', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-001-tuning', display_name='Gemini 1.5 Flash 001 Tuning', description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=16384, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createTunedModel'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash', display_name='Gemini 1.5 Flash', description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-002', display_name='Gemini 1.5 Flash 002', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b', display_name='Gemini 1.5 Flash-8B', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-001', display_name='Gemini 1.5 Flash-8B 001', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-latest', display_name='Gemini 1.5 Flash-8B Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0827', display_name='Gemini 1.5 Flash 8B Experimental 0827', description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-1.5-flash-8b-exp-0924', display_name='Gemini 1.5 Flash 8B Experimental 0924', description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-exp-03-25', display_name='Gemini 2.5 Pro Experimental 03-25', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-03-25', display_name='Gemini 2.5 Pro Preview 03-25', description='Gemini 2.5 Pro Preview 03-25', version='2.5-preview-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-05-20', display_name='Gemini 2.5 Flash Preview 05-20', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-05-20', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17-thinking', display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-05-06', display_name='Gemini 2.5 Pro Preview 05-06', description='Preview release (May 6th, 2025) of Gemini 2.5 Pro', version='2.5-preview-05-06', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-06-05', display_name='Gemini 2.5 Pro Preview', description='Preview release (June 5th, 2025) of Gemini 2.5 Pro', version='2.5-preview-06-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp', display_name='Gemini 2.0 Flash Experimental', description='Gemini 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash', display_name='Gemini 2.0 Flash', description='Gemini 2.0 Flash', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-001', display_name='Gemini 2.0 Flash 001', description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-exp-image-generation', display_name='Gemini 2.0 Flash (Image Generation) Experimental', description='Gemini 2.0 Flash (Image Generation) Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-001', display_name='Gemini 2.0 Flash-Lite 001', description='Stable version of Gemini 2.0 Flash Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite', display_name='Gemini 2.0 Flash-Lite', description='Gemini 2.0 Flash-Lite', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-preview-image-generation', display_name='Gemini 2.0 Flash Preview Image Generation', description='Gemini 2.0 Flash Preview Image Generation', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview-02-05', display_name='Gemini 2.0 Flash-Lite Preview 02-05', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview', display_name='Gemini 2.0 Flash-Lite Preview', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp', display_name='Gemini 2.0 Pro Experimental', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-pro-exp-02-05', display_name='Gemini 2.0 Pro Experimental 02-05', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-exp-1206', display_name='Gemini Experimental 1206', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-01-21', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-1219', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-tts', display_name='Gemini 2.5 Flash Preview TTS', description='Gemini 2.5 Flash Preview TTS', version='gemini-2.5-flash-exp-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-tts', display_name='Gemini 2.5 Pro Preview TTS', description='Gemini 2.5 Pro Preview TTS', version='gemini-2.5-pro-preview-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=65536, output_token_limit=65536, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/learnlm-2.0-flash-experimental', display_name='LearnLM 2.0 Flash Experimental', description='LearnLM 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=32768, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-1b-it', display_name='Gemma 3 1B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-4b-it', display_name='Gemma 3 4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-12b-it', display_name='Gemma 3 12B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3-27b-it', display_name='Gemma 3 27B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=131072, output_token_limit=8192, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemma-3n-e4b-it', display_name='Gemma 3n E4B', description=None, version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=2048, supported_actions=['generateContent', 'countTokens'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/embedding-001', display_name='Embedding 001', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/text-embedding-004', display_name='Text Embedding 004', description='Obtain a distributed representation of a text.', version='004', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-embedding-exp-03-07', display_name='Gemini Embedding Experimental 03-07', description='Obtain a distributed representation of a text.', version='exp-03-07', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8192, output_token_limit=1, supported_actions=['embedContent', 'countTextTokens'], default_checkpoint_id=None, checkpoints=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list().page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e123e091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An histopathological image of a <> region.',\n",
       " 'The central area shows features consistent with <> tissue.',\n",
       " 'This lymph node patch displays characteristics of a <> infiltrate.',\n",
       " 'Observe the cellular morphology within this <> area.',\n",
       " 'The predominant feature of this patch is <> architecture.',\n",
       " 'The nuclear pleomorphism is indicative of a <> process.',\n",
       " 'The staining intensity suggests a <> composition.',\n",
       " 'The density of cells in this region is typical of <> tissue.',\n",
       " 'The presence of mitotic figures suggests a <> state.',\n",
       " 'The stromal reaction is characteristic of <> involvement.',\n",
       " 'The overall pattern is consistent with a <> response.',\n",
       " 'This patch exhibits features of <> lymphocytes.',\n",
       " 'The arrangement of cells suggests a <> origin.',\n",
       " 'The size and shape of nuclei are consistent with <> cells.',\n",
       " 'The cytoplasm staining is indicative of a <> phenotype.',\n",
       " 'The presence of necrosis suggests a <> condition.',\n",
       " 'The inflammatory response appears to be <>.',\n",
       " 'The vascularity within this region is typical of <> tissue.',\n",
       " 'The fibrosis observed is consistent with <> changes.',\n",
       " 'The cellularity is markedly increased in this <> area.',\n",
       " 'The nuclei are hyperchromatic in this <> region.',\n",
       " 'The architectural pattern is disrupted in the <> tissue.',\n",
       " 'The stromal component is prominent in this <> patch.',\n",
       " 'The overall impression is that of a <> process.',\n",
       " 'The cells exhibit atypical features consistent with <> cells.',\n",
       " 'The presence of giant cells suggests a <> reaction.',\n",
       " 'The distribution of cells is uniform in this <> area.',\n",
       " 'The nuclei are round and regular in this <> tissue.',\n",
       " 'The cytoplasm is abundant in these <> cells.',\n",
       " 'The staining is pale in this <> region.',\n",
       " 'The cellular borders are distinct in this <> area.',\n",
       " 'The nuclei are vesicular in this <> tissue.',\n",
       " 'The architectural pattern is well-preserved in the <> tissue.',\n",
       " 'The stromal component is sparse in this <> patch.',\n",
       " 'The overall impression is that of a <> response.',\n",
       " 'The cells exhibit features of <> differentiation.',\n",
       " 'The presence of lymphocytes suggests a <> response.',\n",
       " 'The distribution of cells is irregular in this <> area.',\n",
       " 'The nuclei are irregular in shape in this <> tissue.',\n",
       " 'The cytoplasm is scant in these <> cells.',\n",
       " 'The staining is intense in this <> region.',\n",
       " 'The cellular borders are indistinct in this <> area.',\n",
       " 'The nuclei are densely packed in this <> tissue.',\n",
       " 'The architectural pattern is disorganized in the <> tissue.',\n",
       " 'The stromal component is dense in this <> patch.',\n",
       " 'The overall impression is that of a <> process.',\n",
       " 'The cells show evidence of <> activity.',\n",
       " 'The presence of plasma cells suggests a <> response.',\n",
       " 'The arrangement of cells is follicular in this <> area.',\n",
       " 'The nuclei are enlarged in this <> tissue.',\n",
       " 'The cytoplasm is eosinophilic in these <> cells.',\n",
       " 'The staining is granular in this <> region.',\n",
       " 'The cellular morphology is consistent with <> cells.',\n",
       " 'The nuclei are binucleated in this <> tissue.',\n",
       " 'The architectural pattern is nodular in the <> tissue.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "def extract_and_parse_multi_class_prompt_list(code: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    From a string of Python code, finds the first occurrence of\n",
    "        = [ ... ]\n",
    "    and parses that bracketed literal into a List[str].\n",
    "\n",
    "    The string in the list contains a placeholder <>,\n",
    "\n",
    "    Raises:\n",
    "        ValueError if no list literal is found or it’s malformed,\n",
    "                   or if the parsed list does not contain only strings.\n",
    "    \"\"\"\n",
    "    # 1) Grab everything from the first '=' up to the matching ']'\n",
    "    # This regex is made more robust to handle various whitespace and content within the list.\n",
    "    m = re.search(r'=\\s*(\\[[^\\]]*\\])', code, re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"No list literal found after an '=' in the code\")\n",
    "    list_str = m.group(1)\n",
    "\n",
    "    # 2) Safely evaluate it (only literals)\n",
    "    try:\n",
    "        data: Any = ast.literal_eval(list_str)\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        raise ValueError(f\"Malformed list literal: {e}\")\n",
    "\n",
    "    # 3) Validate shape: ensure it's a list of strings\n",
    "    if not isinstance(data, list) or not all(isinstance(item, str) for item in data):\n",
    "        raise ValueError(\n",
    "            \"Parsed object is not a list of strings, or contains non-string elements.\"\n",
    "        )\n",
    "\n",
    "    # 4) Return the list of strings\n",
    "    return data\n",
    "\n",
    "code = \"\"\"prompts: list[str] = [\n",
    "    \"An histopathological image of a <> region.\",\n",
    "    \"The central area shows features consistent with <> tissue.\",\n",
    "    \"This lymph node patch displays characteristics of a <> infiltrate.\",\n",
    "    \"Observe the cellular morphology within this <> area.\",\n",
    "    \"The predominant feature of this patch is <> architecture.\",\n",
    "    \"The nuclear pleomorphism is indicative of a <> process.\",\n",
    "    \"The staining intensity suggests a <> composition.\",\n",
    "    \"The density of cells in this region is typical of <> tissue.\",\n",
    "    \"The presence of mitotic figures suggests a <> state.\",\n",
    "    \"The stromal reaction is characteristic of <> involvement.\",\n",
    "    \"The overall pattern is consistent with a <> response.\",\n",
    "    \"This patch exhibits features of <> lymphocytes.\",\n",
    "    \"The arrangement of cells suggests a <> origin.\",\n",
    "    \"The size and shape of nuclei are consistent with <> cells.\",\n",
    "    \"The cytoplasm staining is indicative of a <> phenotype.\",\n",
    "    \"The presence of necrosis suggests a <> condition.\",\n",
    "    \"The inflammatory response appears to be <>.\",\n",
    "    \"The vascularity within this region is typical of <> tissue.\",\n",
    "    \"The fibrosis observed is consistent with <> changes.\",\n",
    "    \"The cellularity is markedly increased in this <> area.\",\n",
    "    \"The nuclei are hyperchromatic in this <> region.\",\n",
    "    \"The architectural pattern is disrupted in the <> tissue.\",\n",
    "    \"The stromal component is prominent in this <> patch.\",\n",
    "    \"The overall impression is that of a <> process.\",\n",
    "    \"The cells exhibit atypical features consistent with <> cells.\",\n",
    "    \"The presence of giant cells suggests a <> reaction.\",\n",
    "    \"The distribution of cells is uniform in this <> area.\",\n",
    "    \"The nuclei are round and regular in this <> tissue.\",\n",
    "    \"The cytoplasm is abundant in these <> cells.\",\n",
    "    \"The staining is pale in this <> region.\",\n",
    "    \"The cellular borders are distinct in this <> area.\",\n",
    "    \"The nuclei are vesicular in this <> tissue.\",\n",
    "    \"The architectural pattern is well-preserved in the <> tissue.\",\n",
    "    \"The stromal component is sparse in this <> patch.\",\n",
    "    \"The overall impression is that of a <> response.\",\n",
    "    \"The cells exhibit features of <> differentiation.\",\n",
    "    \"The presence of lymphocytes suggests a <> response.\",\n",
    "    \"The distribution of cells is irregular in this <> area.\",\n",
    "    \"The nuclei are irregular in shape in this <> tissue.\",\n",
    "    \"The cytoplasm is scant in these <> cells.\",\n",
    "    \"The staining is intense in this <> region.\",\n",
    "    \"The cellular borders are indistinct in this <> area.\",\n",
    "    \"The nuclei are densely packed in this <> tissue.\",\n",
    "    \"The architectural pattern is disorganized in the <> tissue.\",\n",
    "    \"The stromal component is dense in this <> patch.\",\n",
    "    \"The overall impression is that of a <> process.\",\n",
    "    \"The cells show evidence of <> activity.\",\n",
    "    \"The presence of plasma cells suggests a <> response.\",\n",
    "    \"The arrangement of cells is follicular in this <> area.\",\n",
    "    \"The nuclei are enlarged in this <> tissue.\",\n",
    "    \"The cytoplasm is eosinophilic in these <> cells.\",\n",
    "    \"The staining is granular in this <> region.\",\n",
    "    \"The cellular morphology is consistent with <> cells.\",\n",
    "    \"The nuclei are binucleated in this <> tissue.\",\n",
    "    \"The architectural pattern is nodular in the <> tissue.\"\n",
    "]\"\"\"\n",
    "extract_and_parse_multi_class_prompt_list(code=code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea0c47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's formulate a strategy to generate high-scoring prompts, and then implement it in Python.\n",
      "\n",
      "**Strategy:**\n",
      "\n",
      "The current top prompts focus on broad descriptions of the tissue and its context (lymph node, biopsy).  To improve, we need to:\n",
      "\n",
      "1. **Specificity:**  Move beyond just \"tissue\" and mention cellular characteristics. Histopathology is about *cells*.\n",
      "2. **Discriminative Features:** Focus on features that *differentiate* tumor from normal.  This means things like cellularity, nuclear features (size, shape, staining), mitotic activity, and architectural patterns.\n",
      "3. **Actionable Verbs:** Use verbs that encourage detailed description (\"assess\", \"evaluate\", \"describe\").  \"Characterize\" is good, but we can do better.\n",
      "4. **Avoid Redundancy:**  Ensure the new prompts are distinct from the existing ones.\n",
      "5. **Contextualize:** Keep the lymph node context, as that's important.\n",
      "\n",
      "Here are some ideas for features to include:\n",
      "\n",
      "*   **Cellularity:**  Dense vs. sparse cell populations.\n",
      "*   **Nuclear Morphology:**  Nuclear size, shape, chromatin pattern, nucleoli.\n",
      "*   **Mitotic Activity:** Presence or absence of dividing cells.\n",
      "*   **Inflammation:** Presence and type of inflammatory cells.\n",
      "*   **Necrosis:** Presence of dead cells.\n",
      "*   **Architectural Pattern:** Disorganized vs. organized structure.\n",
      "*   **Lymphocyte subtypes:** Presence of specific lymphocyte populations.\n",
      "\n",
      "**Python Code:**\n",
      "\n",
      "```python\n",
      "prompts: list[str] = [\n",
      "    \"Describe the cellularity and nuclear morphology of the <> tissue within a lymph node.\",\n",
      "    \"Assess the presence and characteristics of any atypical cells in this <> lymph node section.\",\n",
      "    \"Evaluate the architectural pattern and stromal features of the <> tissue in the lymph node.\",\n",
      "    \"Characterize the degree of lymphocyte infiltration and any evidence of inflammation in the <> region of the lymph node.\",\n",
      "    \"Describe the nuclear-to-cytoplasmic ratio and chromatin texture of cells in the <> lymph node tissue.\",\n",
      "    \"Identify and quantify any mitotic figures present in the <> tissue from a lymph node biopsy.\",\n",
      "    \"Assess for the presence of necrosis or other signs of cell death within the <> lymph node area.\",\n",
      "    \"Describe the distribution and morphology of lymphocytes in the <> region of the lymph node.\",\n",
      "    \"Evaluate the uniformity of cell size and shape within the <> tissue of a lymph node section.\",\n",
      "    \"Characterize the stromal reaction and its relationship to the cellular components in the <> lymph node tissue.\"\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "from API_KEY import GEMINI_API_KEY\n",
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "for i in range(1):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemma-3-27b-it\", contents=\"\"\"The task is to generate distinct textual description prompts of visual discriminative features to describe the central region of an histopathological image patch. The patch is extracted from an H&E‑stained whole‑slide image of a lymph node section. The patch can be either tumor or normal tissue.\n",
    "Each prompt should have a placeholder <> that can be replaced with either \"tumor\" or \"normal\". I will fill in the placeholder later.\n",
    "Here are the best performing pairs in ascending order. High scores indicate higher quality visual discriminative features.\n",
    "Current Top 10 Prompts:\n",
    "1. An histopathological image of a <> lymph node section. Score: 80\n",
    "2. A high-magnification view of <> tissue from a lymph node biopsy. Score: 75\n",
    "3. Characterize the stromal components and their relationship to the <> Score: 74\n",
    "\n",
    "Write 10 new prompts that are different to from the old ones and has a score as high as possible. Formulate a strategy\n",
    "Output as python code in the format - prompts: list[prompt:str]. Let's think step-by-step\n",
    "\"\"\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bead94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break this down. We need to generate 20 prompts, each designed to elicit a description of a histopathological image patch, focusing on the central region. Each prompt will contain a medical concept and a selector with two options – one typical of normal lymph node tissue and one typical of tumor involvement.  The prompts should be phrased so that the resulting sentence makes sense regardless of which option is chosen.  We'll use Python to store these as a list of strings.\n",
      "\n",
      "Here's a step-by-step thought process and then the Python code:\n",
      "\n",
      "1. **Identify Key Histopathological Features:**  We need to think about what features pathologists look at in lymph node H&E sections. These include:\n",
      "    *   Cellularity (how many cells are present)\n",
      "    *   Lymphocyte morphology (size, shape, nucleus, cytoplasm)\n",
      "    *   Presence of mitoses (cell division)\n",
      "    *   Presence of necrosis (cell death)\n",
      "    *   Capsular integrity\n",
      "    *   Follicular structure (if present)\n",
      "    *   Stromal characteristics (amount of connective tissue, edema)\n",
      "    *   Presence of atypical cells/blasts\n",
      "    *   Infiltration patterns\n",
      "\n",
      "2. **Create Normal/Tumor Contrasts:** For each feature, we need to identify what a normal appearance would be versus what a tumorous appearance might be.\n",
      "\n",
      "3. **Formulate Prompts:**  We'll construct prompts using a consistent structure:  \"[Medical Concept] is [<Normal Observation>, <Tumor Observation>]\".\n",
      "\n",
      "4. **Ensure Meaningful Sentences:**  The prompts must read naturally with either option filled in.\n",
      "\n",
      "5. **Generate 20 Distinct Prompts:**  We'll aim for variety in the features assessed.\n",
      "\n",
      "```python\n",
      "prompts: list[str] = [\n",
      "    \"The overall cellularity is [<normal, dense>]\",\n",
      "    \"The lymphocyte morphology is [<small and mature, large and atypical>]\",\n",
      "    \"The number of mitotic figures is [<rare, frequent>]\",\n",
      "    \"The stromal component is [<fibrotic, edematous>]\",\n",
      "    \"The presence of necrosis is [<absent, present>]\",\n",
      "    \"The capsular integrity is [<intact, disrupted>]\",\n",
      "    \"The follicular structure is [<well-defined, effaced>]\",\n",
      "    \"The chromatin pattern of the lymphocytes is [<evenly distributed, vesicular>]\",\n",
      "    \"The nucleoli of the cells are [<small and inconspicuous, prominent and multiple>]\",\n",
      "    \"The cytoplasm of the lymphocytes is [<scant, abundant>]\",\n",
      "    \"The pattern of infiltration is [<none, diffuse>]\",\n",
      "    \"The presence of plasma cells is [<few, numerous>]\",\n",
      "    \"The size of the lymphocytes is [<uniform, variable>]\",\n",
      "    \"The shape of the nuclei is [<regular, irregular>]\",\n",
      "    \"The staining intensity of the nuclei is [<moderate, dark>]\",\n",
      "    \"The amount of interfollicular space is [<normal, increased>]\",\n",
      "    \"The presence of reactive germinal centers is [<yes, no>]\",\n",
      "    \"The vascularity of the tissue is [<normal, increased>]\",\n",
      "    \"The presence of granulomas is [<absent, present>]\",\n",
      "    \"The architectural pattern is [<organized, disorganized>]\"\n",
      "]\n",
      "\n",
      "# Example usage (printing the prompts)\n",
      "for prompt in prompts:\n",
      "    print(prompt)\n",
      "```\n",
      "\n",
      "Key improvements and explanations:\n",
      "\n",
      "*   **Clear Structure:** The prompts consistently follow the \"[Medical Concept] is [<Normal Observation>, <Tumor Observation>]\" format.\n",
      "*   **Meaningful Options:** The normal and tumor options are chosen to create grammatically correct and understandable sentences when either is selected.\n",
      "*   **Variety of Features:** The prompts cover a range of histopathological features relevant to lymph node assessment.\n",
      "*   **Specificity:** The observations are relatively specific (e.g., \"vesicular\" chromatin vs. \"evenly distributed\").\n",
      "*   **Python List:** The prompts are stored in a Python list as requested.\n",
      "*   **Type Hinting:** Added type hinting for clarity.\n",
      "*   **Example Usage:** Included a loop to print the prompts for easy review.\n",
      "*   **Realistic Observations:** The observations are based on what a pathologist would actually look for.\n",
      "*   **Avoidance of Ambiguity:**  The prompts are designed to minimize ambiguity in interpretation.\n",
      "*   **Conciseness:** The prompts are concise and to the point.\n",
      "*   **Correctness:** The prompts are medically sound and reflect the differences between normal and tumorous lymph node tissue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "from API_KEY import GEMINI_API_KEY\n",
    "import re\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "for i in range(1):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemma-3-27b-it\", contents=\"\"\"The task is to generate 20 distinct textual description prompts of visual discriminative features to describe the central region of an histopathological image patch. The patch is extracted from an H&E‑stained whole‑slide image of a lymph node section. The patch can be either tumor or normal tissue.\n",
    "Each prompt should have the multiple options for each class 'normal' and 'tumor'. In each prompt, along with the medical concept add an selector in the format: '[normal observation, tumor observation]'. The text should be meaningful after when one of the options is filled.\n",
    "\n",
    "Eg: The stromal component is ['fibrotic', 'edematous']\n",
    "Output as python code in the format - prompts: list[prompt:str]. Let's think step-by-step\n",
    "\"\"\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38b03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
